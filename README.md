# Nautilopy: 3D Underwater Cave Mapping with Sonar Technology
Thomas Guilment, Gabriele Morra, Orhun Aydin, Stefany Carty

- [Nautilopy](#nautilopy)
  - [Project Overview](#project-overview)
  - [Sonar Specifications](#sonar-specifications)
  - [Available Data in Python](#available-data-in-python)
  - [Current/Future work](#currentfuture-work)
  - [Project Folder architecture
    Template](#project-folder-architecture-template)
  - [Developer Guide](#developer-guide)
  - [Usage](#usage)
  - [How to use](#how-to-use)

<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->

# Nautilopy

<div style="display: flex; justify-content: space-between; align-items: center; max-width: 2000px; margin: 0 auto; padding: 20px;">

<div style="display: flex; flex-direction: column; align-items: center; padding-top: 50px;">

    <img src="./img/Logo_Jupyter.png" style="width: 100px; height: 100px;">

</div>

<div style="display: flex; flex-direction: column; align-items: center; padding: 0 100px;">

    <img src="./img/Logo_nautilopy_tiny.png" style="width: 200px; height: 200px;">

</div>

<div style="display: flex; flex-direction: column; align-items: center; padding-top: 50px;">

    <img src="./img/Logo_Python.png" style="width: 100px; height: 100px;">

</div>

</div>

<!-- ::: {layout-ncol=3}
![](./img/Logo_Jupyter.png)
![](./img/Logo_nautilopy_tiny.png)
![](./img/Logo_Python.png)
::: -->

## Project Overview

Nautilopy is a Python module for 3D underwater cave mapping using sonar
technology. This library provides tools and algorithms to process sonar
data, generate 3D models of underwater cave systems, and visualize
complex submerged environments.

### Dataset Description

The dataset, provided by Angelos Maillos et *al.* 2017, includes sensor
data collected during an AUV mission in July 2013. A diver guided the
AUV due to the spatial complexity of the caves.

### Sensor Suite

- Two mechanically scanned imaging sonars (MSIS)
- Doppler velocity log (DVL)
- Two inertial measurement units (IMUs)
- Depth sensor
- Vertically mounted camera (for ground truth validation)

### Available Data Topics from CSV files

1.  `/depth_sensor`: DS2806 HPS-A pressure sensor data
2.  `/dvl_linkquest`: LinkQuest NavQuest 600 sensor data
3.  `/imu_adis`: Analog Devices ADIS16480 sensor data
4.  `/imu_adis_ros`: ADIS16480 orientation in standard ROS format
5.  `/imu_xsens_mti`: Xsens MTi sensor data
    <!-- REMOVED (FILE TOO LARGE) 6. `/imu_xsens_mti_ros`: Xsens MTi orientation in standard ROS format -->
6.  `/odometry`: Robot pose estimation
7.  `/sonar_micron`: Tritech Micron DST sensor beam data
8.  `/sonar_micron_ros`: Micron data in standard ROS Laserscan format
9.  `/sonar_seaking`: Tritech Super SeaKing DFP profiler sensor beam
    data
    <!-- REMOVED (FILE TOO LARGE) 11. `/sonar_seaking_ros`: Profiler data in standard ROS Laserscan format -->
10. `/tf`: Sensor offset transformations

## Sonar Specifications

| Specification | Imaging sonar - Tritech Micron DST | Profiling sonar - Tritech Super SeaKing DFP |
|----|----|----|
| Frequency | Chirped 650 to 750 kHz | 0.6 MHz \| 1.1 MHz |
| Max range | 75 m (20 m used) | 80 m \| 40 m (10 m used) |
| Horizontal beamwidth | 3° | 2° \| 1° |
| Vertical beamwidth | 35° | 2° \| 1° |
| Scan rate (360° sector) | 5 − 20 sec | 4 − 25 sec |

## Available Data in Python

A pre-processing is done on the CSV sensors data to create a Pickle
folder containing the following interpolated variables.

### 1. Horizontal Micron Sonar Data

- `v_timestamp_sonar_micron_final`: Timestamps
- `m_sonarReceivedIntensity_micron_final`: (397x45587) Received energy
  per range and time
- `m_interp_micron_YPR`: (45587x3) Yaw, Pitch, Roll over time
- `m_interp_pos_micron_final`: (45587x3) 3D Cartesian position over time
- `v_angles_rad_micron_final`: (45587x1) Scanning angle over time
  (radians)
- `v_range_micron`: (397x1) Range values (0 to 20 meters)
- `v_offset_ypr_micron`: (3x1) Offset position from AUV reference

### 2. Vertical Seaking Sonar Data

- `v_timestamp_sonar_seaking_final`: Timestamps
- `m_sonarReceivedIntensity_seaking_final`: (50x97477) Received energy
  per range and time
- `m_interp_micron_YPR`: (97477x3) Yaw, Pitch, Roll over time
- `m_interp_pos_micron_final`: (97477x3) 3D Cartesian position over time
- `v_angles_rad_micron_final`: (97477x1) Scanning angle over time
  (radians)
- `v_range_micron`: (50x1) Range values (0 to 20 meters)
- `v_offset_ypr_seaking`: (3x1) Offset position from AUV reference

## Current/Future work

1.  **Walls segmentation**  
    How to automatically extract the cave walls from sonar and sensor
    data? One idea is to annotate what we think is wall data and then
    apply AI/ML algorithms.

2.  **3D confidence map**  
    From the wall segmentation, we should be able to get a first 3D map
    with a confidence level assigned for each point according to the
    “wall segmentation” confidence algorithm.

3.  **3D confidence map extension by interpolation/extrapolation**  
    The final map could be interpolated to understand the entire cave.
    This interpolation could also have a confidence level depending on
    how far it is from the base 3D map.

4.  **Photogrammetry**  
    We have the video that should help add an extra data source. We
    could use the video combined with the altitude estimation to use the
    3D photogrammetry and correlate the detected point of interest with
    the 3D map made from the sonar

5.  **SLAM**  
    Compared to the work from Maillos *et al.*, 2015), the authors used
    simultaneous localization and mapping (SLAM) methods that I didn’t
    use. This is supposed to improve the 3D position of the AUV
    (Autonomous Underwater Vehicle) and improve the 3D map quality.

6.  **Real-time and Optimization**  
    When we have a SLAM method that we trust and everything is working.
    Then, we can think of real-time mapping and confidence map creation.

This file will become your README and also the index of your
documentation.

## Project Folder architecture Template

    project_root/
    ├── nbs/                 # Jupyter notebooks
    │   ├── 00_core.ipynb
    │   ├── 01_data.ipynb
    │   ├── 02_model.ipynb
    │   └── 03_evaluation.ipynb
    ├── nautilopy/           # Auto-generated Python modules
    ├── docs/                # Auto-generated documentation
    ├── tests/               # Additional tests (if needed)
    ├── data/                # Data files (consider .gitignore for large files)
    ├── models/              # Saved model files
    ├── settings.ini         # nbdev configuration
    ├── README.md
    └── LICENSE

## Developer Guide

Recommendation: read the End-To-Edn Walkthrough from the
[Tutorial](https://nbdev.fast.ai/tutorials/tutorial.html)  
If you are new to using `nbdev` here are some useful pointers to get you
started.

### Install nautilopy in Development mode

``` sh
# make sure nautilopy package is installed in development mode
$ pip install -e .

# make changes under nbs/ directory
# ...

# compile to have changes apply to nautilopy
$ nbdev_prepare
```

## Usage

### Installation

Install the latest from the GitHub
[repository](https://github.com/20KUTS/nautilopy):

``` sh
$ pip install git+https://github.com/20KUTS/nautilopy.git
```

or from [conda](https://anaconda.org/20KUTS/nautilopy)

``` sh
$ conda install -c 20KUTS nautilopy
```

or mamba
[mamba](https://mamba.readthedocs.io/en/latest/installation/mamba-installation.html)

``` sh
$ mamba install -c 20KUTS nautilopy
```

or from [pypi](https://pypi.org/project/nautilopy/)

``` sh
$ pip install nautilopy
```

### Documentation

Documentation can be found hosted on this GitHub
[repository](https://github.com/20KUTS/nautilopy)’s
[pages](https://20KUTS.github.io/nautilopy/). Additionally, you can find
package manager-specific guidelines on
[conda](https://anaconda.org/20KUTS/nautilopy) and
[pypi](https://pypi.org/project/nautilopy/) respectively.

## How to use

TO DO (redirect to notebooks later)

``` python
1+1
```

    2
